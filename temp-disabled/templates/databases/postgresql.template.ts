/**
 * PostgreSQL Advanced Database Template
 * P3-T01 Implementation for CodeRunner v2.0
 * 
 * Features:
 * - Multi-tenant architecture with schema/database/row-level isolation
 * - AgentSphere cloud integration
 * - Advanced backup, monitoring, and migration capabilities
 * - High availability and disaster recovery
 * - Auto-scaling and performance optimization
 */

import {
  PostgreSQLTemplate,
  PostgreSQLDeploymentResult,
  PostgreSQLTenant,
  validatePostgreSQLTemplate,
  DEFAULT_POSTGRESQL_TEMPLATE,
  ENVIRONMENT_PRESETS
} from './postgresql.config';

/**
 * PostgreSQL template class for managing advanced database deployments
 */
export class PostgreSQLDatabaseTemplate {
  private template: PostgreSQLTemplate;
  private tenants: Map<string, PostgreSQLTenant>;
  private deploymentHistory: PostgreSQLDeploymentResult[];

  constructor(template?: Partial<PostgreSQLTemplate>) {
    this.template = {
      ...DEFAULT_POSTGRESQL_TEMPLATE,
      ...template
    } as PostgreSQLTemplate;
    
    this.tenants = new Map();
    this.deploymentHistory = [];
    
    // Apply environment-specific presets
    if (template?.environment && ENVIRONMENT_PRESETS[template.environment]) {
      this.applyEnvironmentPreset(template.environment);
    }
  }

  /**
   * Apply environment-specific configuration preset
   */
  private applyEnvironmentPreset(environment: string): void {
    const preset = ENVIRONMENT_PRESETS[environment];
    if (preset) {
      this.template = this.mergeDeep(this.template, preset) as PostgreSQLTemplate;
    }
  }

  /**
   * Deep merge two objects
   */
  private mergeDeep(target: any, source: any): any {
    const result = { ...target };
    
    for (const key in source) {
      if (source[key] && typeof source[key] === 'object' && !Array.isArray(source[key])) {
        result[key] = this.mergeDeep(result[key] || {}, source[key]);
      } else {
        result[key] = source[key];
      }
    }
    
    return result;
  }

  /**
   * Get the current template configuration
   */
  getTemplate(): PostgreSQLTemplate {
    return { ...this.template };
  }

  /**
   * Update template configuration
   */
  updateTemplate(updates: Partial<PostgreSQLTemplate>): void {
    this.template = { ...this.template, ...updates };
    this.template.updated_at = new Date();
  }

  /**
   * Validate the current template configuration
   */
  validate(): { isValid: boolean; errors: { [field: string]: string[] } } {
    return validatePostgreSQLTemplate(this.template);
  }

  /**
   * Generate PostgreSQL configuration files
   */
  generatePostgreSQLConfig(): string {
    const config = this.template;
    
    return `
# PostgreSQL Configuration
# Generated by CodeRunner v2.0 PostgreSQL Template
# Template: ${config.name}
# Version: ${config.version}
# Environment: ${config.environment}

# Connection Settings
max_connections = ${config.performance.max_connections}
port = 5432

# Memory Settings
shared_buffers = ${config.performance.shared_buffers}
effective_cache_size = ${config.performance.effective_cache_size}
maintenance_work_mem = ${config.performance.maintenance_work_mem}
work_mem = ${config.performance.work_mem}

# WAL Settings
wal_buffers = ${config.performance.wal_buffers}
checkpoint_completion_target = ${config.performance.checkpoint_completion_target}

# Query Planner Settings
random_page_cost = ${config.performance.random_page_cost}

# Logging Settings
log_statement = 'all'
log_min_duration_statement = ${config.features.monitoring.slow_query_threshold}
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '

# SSL Settings
ssl = ${config.security.ssl_enabled ? 'on' : 'off'}
${config.security.ssl_enabled ? `ssl_cert_file = '/etc/ssl/certs/server.crt'
ssl_key_file = '/etc/ssl/private/server.key'` : ''}

# Password Encryption
password_encryption = ${config.security.password_encryption}

# Row Level Security
row_security = ${config.security.row_level_security ? 'on' : 'off'}

# Replication Settings (if enabled)
${config.features.replication.enabled ? `
wal_level = replica
max_wal_senders = ${config.features.replication.replicas + 2}
max_replication_slots = ${config.features.replication.replicas + 2}
synchronous_standby_names = '${config.features.replication.sync_mode === 'synchronous' ? '*' : ''}'
` : ''}

# Extensions
shared_preload_libraries = '${config.extensions.join(',')}'

# Custom Settings
timezone = 'UTC'
datestyle = 'iso, mdy'
default_text_search_config = 'pg_catalog.english'
`;
  }

  /**
   * Generate Docker Compose configuration for PostgreSQL
   */
  generateDockerCompose(): string {
    const config = this.template;
    
    return `
version: '3.8'

services:
  postgresql-${config.name}:
    image: postgres:${config.version}-alpine
    container_name: postgresql-${config.name}
    restart: always
    environment:
      POSTGRES_DB: ${config.name}
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: \${POSTGRES_PASSWORD}
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgresql_data:/var/lib/postgresql/data
      - ./postgresql.conf:/etc/postgresql/postgresql.conf:ro
      - ./init-scripts:/docker-entrypoint-initdb.d:ro
    command: postgres -c config_file=/etc/postgresql/postgresql.conf
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - postgresql_network
    ${config.scaling.auto_scaling ? `deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G` : ''}

  ${config.features.monitoring.enabled ? `postgresql-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: postgresql-exporter-${config.name}
    restart: always
    environment:
      DATA_SOURCE_NAME: postgresql://postgres:\${POSTGRES_PASSWORD}@postgresql-${config.name}:5432/${config.name}?sslmode=disable
    ports:
      - "9187:9187"
    depends_on:
      - postgresql-${config.name}
    networks:
      - postgresql_network` : ''}

  ${config.features.backup.enabled ? `postgresql-backup:
    image: prodrigestivill/postgres-backup-local:latest
    container_name: postgresql-backup-${config.name}
    restart: always
    environment:
      POSTGRES_HOST: postgresql-${config.name}
      POSTGRES_DB: ${config.name}
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: \${POSTGRES_PASSWORD}
      SCHEDULE: "${config.features.backup.schedule}"
      BACKUP_KEEP_DAYS: ${config.features.backup.retention_days}
      BACKUP_KEEP_WEEKS: 4
      BACKUP_KEEP_MONTHS: 6
    volumes:
      - postgresql_backups:/backups
    depends_on:
      - postgresql-${config.name}
    networks:
      - postgresql_network` : ''}

volumes:
  postgresql_data:
    driver: local
  ${config.features.backup.enabled ? 'postgresql_backups:\n    driver: local' : ''}

networks:
  postgresql_network:
    driver: bridge
`;
  }

  /**
   * Generate initialization scripts for multi-tenant setup
   */
  generateInitScripts(): { [filename: string]: string } {
    const config = this.template;
    const scripts: { [filename: string]: string } = {};

    // Main initialization script
    scripts['01-init-database.sql'] = `
-- PostgreSQL Database Initialization
-- Template: ${config.name}
-- Multi-tenant setup with ${config.tenant_isolation} isolation

-- Enable required extensions
${config.extensions.map(ext => `CREATE EXTENSION IF NOT EXISTS "${ext}";`).join('\n')}

-- Create tenant management schema
CREATE SCHEMA IF NOT EXISTS tenant_management;

-- Create tenant registry table
CREATE TABLE IF NOT EXISTS tenant_management.tenants (
    tenant_id VARCHAR(255) PRIMARY KEY,
    schema_name VARCHAR(255) NOT NULL UNIQUE,
    database_name VARCHAR(255),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    status VARCHAR(50) DEFAULT 'active',
    resource_limits JSONB,
    isolation_config JSONB
);

-- Create tenant audit log
CREATE TABLE IF NOT EXISTS tenant_management.tenant_audit_log (
    id SERIAL PRIMARY KEY,
    tenant_id VARCHAR(255) REFERENCES tenant_management.tenants(tenant_id),
    action VARCHAR(100) NOT NULL,
    details JSONB,
    performed_by VARCHAR(255),
    performed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Create function to automatically create tenant schema
CREATE OR REPLACE FUNCTION tenant_management.create_tenant_schema(
    p_tenant_id VARCHAR(255),
    p_schema_name VARCHAR(255)
)
RETURNS BOOLEAN AS $$
DECLARE
    sql_stmt TEXT;
BEGIN
    -- Create the schema
    sql_stmt := format('CREATE SCHEMA IF NOT EXISTS %I', p_schema_name);
    EXECUTE sql_stmt;
    
    -- Create tenant user role
    sql_stmt := format('CREATE ROLE %I LOGIN PASSWORD %L', 
                      p_tenant_id || '_role', 
                      'temp_password_' || p_tenant_id);
    EXECUTE sql_stmt;
    
    -- Grant schema usage to tenant role
    sql_stmt := format('GRANT USAGE ON SCHEMA %I TO %I', 
                      p_schema_name, 
                      p_tenant_id || '_role');
    EXECUTE sql_stmt;
    
    -- Grant create privileges on schema
    sql_stmt := format('GRANT CREATE ON SCHEMA %I TO %I', 
                      p_schema_name, 
                      p_tenant_id || '_role');
    EXECUTE sql_stmt;
    
    -- Log the action
    INSERT INTO tenant_management.tenant_audit_log (tenant_id, action, details)
    VALUES (p_tenant_id, 'schema_created', 
            jsonb_build_object('schema_name', p_schema_name));
    
    RETURN TRUE;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'Error creating tenant schema: %', SQLERRM;
        RETURN FALSE;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

${config.security.row_level_security ? `
-- Enable row-level security functions
CREATE OR REPLACE FUNCTION tenant_management.current_tenant_id()
RETURNS VARCHAR(255) AS $$
BEGIN
    RETURN current_setting('app.current_tenant_id', true);
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;

-- Create RLS policy function
CREATE OR REPLACE FUNCTION tenant_management.create_tenant_policy(
    p_table_name VARCHAR(255),
    p_schema_name VARCHAR(255)
)
RETURNS BOOLEAN AS $$
DECLARE
    sql_stmt TEXT;
BEGIN
    -- Enable RLS on table
    sql_stmt := format('ALTER TABLE %I.%I ENABLE ROW LEVEL SECURITY', 
                      p_schema_name, p_table_name);
    EXECUTE sql_stmt;
    
    -- Create policy
    sql_stmt := format('CREATE POLICY tenant_isolation ON %I.%I 
                       FOR ALL TO %I 
                       USING (tenant_id = tenant_management.current_tenant_id())', 
                      p_schema_name, p_table_name, p_schema_name || '_role');
    EXECUTE sql_stmt;
    
    RETURN TRUE;
EXCEPTION
    WHEN OTHERS THEN
        RAISE NOTICE 'Error creating tenant policy: %', SQLERRM;
        RETURN FALSE;
END;
$$ LANGUAGE plpgsql SECURITY DEFINER;
` : ''}

-- Create monitoring views
CREATE OR REPLACE VIEW tenant_management.tenant_stats AS
SELECT 
    t.tenant_id,
    t.schema_name,
    t.status,
    (
        SELECT COUNT(*) 
        FROM information_schema.tables 
        WHERE table_schema = t.schema_name
    ) as table_count,
    (
        SELECT pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename))
        FROM pg_tables 
        WHERE schemaname = t.schema_name
        LIMIT 1
    ) as schema_size,
    t.created_at
FROM tenant_management.tenants t;

-- Create indexes for performance
CREATE INDEX IF NOT EXISTS idx_tenants_status ON tenant_management.tenants(status);
CREATE INDEX IF NOT EXISTS idx_audit_log_tenant ON tenant_management.tenant_audit_log(tenant_id);
CREATE INDEX IF NOT EXISTS idx_audit_log_timestamp ON tenant_management.tenant_audit_log(performed_at);
`;

    // Performance monitoring script
    if (config.features.monitoring.enabled) {
      scripts['02-monitoring-setup.sql'] = `
-- Performance Monitoring Setup
-- Enable pg_stat_statements for query analysis
CREATE EXTENSION IF NOT EXISTS pg_stat_statements;

-- Create monitoring schema
CREATE SCHEMA IF NOT EXISTS monitoring;

-- Create custom metrics table
CREATE TABLE IF NOT EXISTS monitoring.performance_metrics (
    id SERIAL PRIMARY KEY,
    metric_name VARCHAR(255) NOT NULL,
    metric_value NUMERIC NOT NULL,
    labels JSONB,
    collected_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Create slow query log view
CREATE OR REPLACE VIEW monitoring.slow_queries AS
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    rows,
    100.0 * shared_blks_hit / nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent
FROM pg_stat_statements 
WHERE mean_time > ${config.features.monitoring.slow_query_threshold}
ORDER BY mean_time DESC
LIMIT 50;

-- Create connection monitoring view
CREATE OR REPLACE VIEW monitoring.connection_stats AS
SELECT 
    state,
    COUNT(*) as connection_count,
    MAX(now() - state_change) as max_duration
FROM pg_stat_activity 
WHERE pid != pg_backend_pid()
GROUP BY state;

-- Create index usage monitoring
CREATE OR REPLACE VIEW monitoring.index_usage AS
SELECT 
    schemaname,
    tablename,
    attname,
    n_distinct,
    correlation,
    most_common_vals
FROM pg_stats 
WHERE schemaname NOT IN ('information_schema', 'pg_catalog', 'pg_toast');
`;
    }

    return scripts;
  }

  /**
   * Generate Kubernetes deployment manifests
   */
  generateKubernetesManifests(): { [filename: string]: string } {
    const config = this.template;
    const manifests: { [filename: string]: string } = {};

    // ConfigMap for PostgreSQL configuration
    manifests['postgresql-config.yaml'] = `
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgresql-config-${config.name}
  labels:
    app: postgresql
    template: ${config.name}
data:
  postgresql.conf: |
${this.generatePostgreSQLConfig().split('\n').map(line => '    ' + line).join('\n')}
`;

    // Secret for PostgreSQL credentials
    manifests['postgresql-secret.yaml'] = `
apiVersion: v1
kind: Secret
metadata:
  name: postgresql-secret-${config.name}
  labels:
    app: postgresql
    template: ${config.name}
type: Opaque
data:
  postgres-password: \${POSTGRES_PASSWORD_BASE64}
  postgres-user: \${POSTGRES_USER_BASE64}
`;

    // StatefulSet for PostgreSQL
    manifests['postgresql-statefulset.yaml'] = `
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql-${config.name}
  labels:
    app: postgresql
    template: ${config.name}
spec:
  serviceName: postgresql-${config.name}
  replicas: 1
  selector:
    matchLabels:
      app: postgresql
      template: ${config.name}
  template:
    metadata:
      labels:
        app: postgresql
        template: ${config.name}
    spec:
      containers:
      - name: postgresql
        image: postgres:${config.version}-alpine
        ports:
        - containerPort: 5432
          name: postgresql
        env:
        - name: POSTGRES_DB
          value: "${config.name}"
        - name: POSTGRES_USER
          valueFrom:
            secretKeyRef:
              name: postgresql-secret-${config.name}
              key: postgres-user
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgresql-secret-${config.name}
              key: postgres-password
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: postgresql-data
          mountPath: /var/lib/postgresql/data
        - name: postgresql-config
          mountPath: /etc/postgresql/postgresql.conf
          subPath: postgresql.conf
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - postgres
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: postgresql-config
        configMap:
          name: postgresql-config-${config.name}
  volumeClaimTemplates:
  - metadata:
      name: postgresql-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: ${config.storage_gb}Gi
`;

    // Service for PostgreSQL
    manifests['postgresql-service.yaml'] = `
apiVersion: v1
kind: Service
metadata:
  name: postgresql-${config.name}
  labels:
    app: postgresql
    template: ${config.name}
spec:
  ports:
  - port: 5432
    targetPort: 5432
    protocol: TCP
    name: postgresql
  selector:
    app: postgresql
    template: ${config.name}
  type: ClusterIP
`;

    // Horizontal Pod Autoscaler (if auto-scaling is enabled)
    if (config.scaling.auto_scaling) {
      manifests['postgresql-hpa.yaml'] = `
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: postgresql-${config.name}
  labels:
    app: postgresql
    template: ${config.name}
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: StatefulSet
    name: postgresql-${config.name}
  minReplicas: ${config.scaling.min_capacity}
  maxReplicas: ${config.scaling.max_capacity}
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: ${config.scaling.scale_up_threshold}
  behavior:
    scaleUp:
      stabilizationWindowSeconds: ${config.scaling.scale_up_cooldown * 60}
    scaleDown:
      stabilizationWindowSeconds: ${config.scaling.scale_down_cooldown * 60}
`;
    }

    return manifests;
  }

  /**
   * Generate backup scripts
   */
  generateBackupScripts(): { [filename: string]: string } {
    const config = this.template;
    const scripts: { [filename: string]: string } = {};

    if (!config.features.backup.enabled) {
      return scripts;
    }

    scripts['backup.sh'] = `#!/bin/bash
# PostgreSQL Backup Script
# Template: ${config.name}
# Generated by CodeRunner v2.0

set -euo pipefail

# Configuration
DB_NAME="${config.name}"
BACKUP_DIR="/backups"
RETENTION_DAYS=${config.features.backup.retention_days}
COMPRESSION="${config.features.backup.compression}"
BACKUP_TYPE="${config.features.backup.backup_type}"
ENCRYPTION=${config.features.backup.encryption_enabled}

# Create backup directory if it doesn't exist
mkdir -p "\$BACKUP_DIR"

# Generate timestamp
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="\$BACKUP_DIR/\${DB_NAME}_\$TIMESTAMP"

# Function to log messages
log() {
    echo "[\$(date '+%Y-%m-%d %H:%M:%S')] \$1" | tee -a "\$BACKUP_DIR/backup.log"
}

# Function to cleanup old backups
cleanup_old_backups() {
    log "Cleaning up backups older than \$RETENTION_DAYS days"
    find "\$BACKUP_DIR" -name "\${DB_NAME}_*" -type f -mtime +\$RETENTION_DAYS -delete
    log "Cleanup completed"
}

# Function to compress backup
compress_backup() {
    local file=\$1
    case \$COMPRESSION in
        gzip)
            log "Compressing backup with gzip"
            gzip "\$file"
            echo "\${file}.gz"
            ;;
        lz4)
            log "Compressing backup with lz4"
            lz4 "\$file" "\${file}.lz4"
            rm "\$file"
            echo "\${file}.lz4"
            ;;
        none)
            echo "\$file"
            ;;
        *)
            log "Unknown compression type: \$COMPRESSION"
            echo "\$file"
            ;;
    esac
}

# Function to encrypt backup
encrypt_backup() {
    local file=\$1
    if [ "\$ENCRYPTION" = "true" ]; then
        log "Encrypting backup"
        openssl enc -aes-256-cbc -salt -in "\$file" -out "\${file}.enc" -k "\$BACKUP_ENCRYPTION_KEY"
        rm "\$file"
        echo "\${file}.enc"
    else
        echo "\$file"
    fi
}

# Main backup function
perform_backup() {
    log "Starting \$BACKUP_TYPE backup of database \$DB_NAME"
    
    case \$BACKUP_TYPE in
        full)
            pg_dump -h localhost -U postgres -d "\$DB_NAME" -f "\${BACKUP_FILE}.sql"
            ;;
        incremental)
            # Use pg_basebackup for incremental backups
            pg_basebackup -h localhost -U postgres -D "\${BACKUP_FILE}_base" -F tar -z -P
            ;;
        *)
            log "Unknown backup type: \$BACKUP_TYPE"
            exit 1
            ;;
    esac
    
    # Process the backup file
    if [ "\$BACKUP_TYPE" = "full" ]; then
        FINAL_FILE="\${BACKUP_FILE}.sql"
        FINAL_FILE=\$(compress_backup "\$FINAL_FILE")
        FINAL_FILE=\$(encrypt_backup "\$FINAL_FILE")
    else
        FINAL_FILE="\${BACKUP_FILE}_base.tar.gz"
        FINAL_FILE=\$(encrypt_backup "\$FINAL_FILE")
    fi
    
    # Calculate backup size and checksum
    BACKUP_SIZE=\$(du -h "\$FINAL_FILE" | cut -f1)
    BACKUP_CHECKSUM=\$(sha256sum "\$FINAL_FILE" | cut -d' ' -f1)
    
    log "Backup completed: \$FINAL_FILE (\$BACKUP_SIZE)"
    log "Checksum: \$BACKUP_CHECKSUM"
    
    # Optional: Upload to S3 if configured
    ${config.features.backup.s3_bucket ? `
    if [ -n "\${AWS_ACCESS_KEY_ID:-}" ] && [ -n "\${AWS_SECRET_ACCESS_KEY:-}" ]; then
        log "Uploading backup to S3"
        aws s3 cp "\$FINAL_FILE" "s3://${config.features.backup.s3_bucket}${config.features.backup.s3_path || '/'}/"
        log "Upload completed"
    fi
    ` : ''}
}

# Function to verify backup
verify_backup() {
    local backup_file=\$1
    log "Verifying backup integrity"
    
    # Check file exists and is not empty
    if [ ! -s "\$backup_file" ]; then
        log "ERROR: Backup file is empty or does not exist"
        exit 1
    fi
    
    # Additional verification based on backup type
    case \$BACKUP_TYPE in
        full)
            # For SQL dumps, check if the file contains valid SQL
            if echo "\$backup_file" | grep -q "\\.sql"; then
                if ! head -n 10 "\$backup_file" | grep -q "PostgreSQL database dump"; then
                    log "WARNING: Backup file may not be a valid PostgreSQL dump"
                fi
            fi
            ;;
    esac
    
    log "Backup verification completed"
}

# Main execution
main() {
    log "Backup process started for \$DB_NAME"
    
    # Check prerequisites
    if ! command -v pg_dump &> /dev/null; then
        log "ERROR: pg_dump is not available"
        exit 1
    fi
    
    # Perform backup
    perform_backup
    
    # Verify backup
    verify_backup "\$FINAL_FILE"
    
    # Cleanup old backups
    cleanup_old_backups
    
    log "Backup process completed successfully"
}

# Error handling
trap 'log "ERROR: Backup process failed at line \$LINENO"; exit 1' ERR

# Run main function
main "\$@"
`;

    scripts['restore.sh'] = `#!/bin/bash
# PostgreSQL Restore Script
# Template: ${config.name}
# Generated by CodeRunner v2.0

set -euo pipefail

# Configuration
DB_NAME="${config.name}"
BACKUP_DIR="/backups"

# Function to log messages
log() {
    echo "[\$(date '+%Y-%m-%d %H:%M:%S')] \$1"
}

# Function to list available backups
list_backups() {
    log "Available backups:"
    ls -la "\$BACKUP_DIR"/\${DB_NAME}_* 2>/dev/null || log "No backups found"
}

# Function to restore from backup
restore_backup() {
    local backup_file=\$1
    
    if [ ! -f "\$backup_file" ]; then
        log "ERROR: Backup file not found: \$backup_file"
        exit 1
    fi
    
    log "Restoring database \$DB_NAME from \$backup_file"
    
    # Decrypt if needed
    if [[ "\$backup_file" == *.enc ]]; then
        log "Decrypting backup"
        openssl enc -d -aes-256-cbc -in "\$backup_file" -out "\${backup_file%.enc}" -k "\$BACKUP_ENCRYPTION_KEY"
        backup_file="\${backup_file%.enc}"
    fi
    
    # Decompress if needed
    if [[ "\$backup_file" == *.gz ]]; then
        log "Decompressing backup"
        gunzip "\$backup_file"
        backup_file="\${backup_file%.gz}"
    elif [[ "\$backup_file" == *.lz4 ]]; then
        log "Decompressing backup"
        lz4 -d "\$backup_file" "\${backup_file%.lz4}"
        backup_file="\${backup_file%.lz4}"
    fi
    
    # Restore the database
    log "Dropping existing database (if exists)"
    psql -h localhost -U postgres -c "DROP DATABASE IF EXISTS \$DB_NAME;"
    
    log "Creating database"
    psql -h localhost -U postgres -c "CREATE DATABASE \$DB_NAME;"
    
    log "Restoring data"
    psql -h localhost -U postgres -d "\$DB_NAME" -f "\$backup_file"
    
    log "Restore completed successfully"
}

# Main function
main() {
    if [ "\$#" -eq 0 ]; then
        list_backups
        echo ""
        echo "Usage: \$0 <backup_file>"
        echo "Example: \$0 /backups/\${DB_NAME}_20240101_120000.sql"
        exit 1
    fi
    
    restore_backup "\$1"
}

main "\$@"
`;

    return scripts;
  }

  /**
   * Add a new tenant to the PostgreSQL instance
   */
  addTenant(tenantId: string, options: Partial<PostgreSQLTenant> = {}): PostgreSQLTenant {
    const tenant: PostgreSQLTenant = {
      tenant_id: tenantId,
      schema_name: `${this.template.schema_prefix}_${tenantId}`,
      created_at: new Date(),
      resource_limits: {
        max_connections: Math.floor(this.template.connection_pool.max / 10),
        storage_quota_mb: 1000,
        cpu_quota_percent: 10
      },
      isolation_config: {
        type: this.template.tenant_isolation,
        access_policies: [],
        ...(this.template.tenant_isolation === 'row' ? { row_security_policies: [] } : {})
      },
      status: 'active',
      ...options
    };

    if (this.template.tenant_isolation === 'database') {
      tenant.database_name = `${this.template.name}_${tenantId}`;
    }

    this.tenants.set(tenantId, tenant);
    return tenant;
  }

  /**
   * Remove a tenant from the PostgreSQL instance
   */
  removeTenant(tenantId: string): boolean {
    if (!this.tenants.has(tenantId)) {
      return false;
    }

    const tenant = this.tenants.get(tenantId)!;
    tenant.status = 'deleting';
    
    // In a real implementation, this would trigger schema/database cleanup
    this.tenants.delete(tenantId);
    return true;
  }

  /**
   * Get all tenants
   */
  getTenants(): PostgreSQLTenant[] {
    return Array.from(this.tenants.values());
  }

  /**
   * Get tenant by ID
   */
  getTenant(tenantId: string): PostgreSQLTenant | undefined {
    return this.tenants.get(tenantId);
  }

  /**
   * Generate deployment summary
   */
  getDeploymentSummary(): any {
    const config = this.template;
    
    return {
      template_name: config.name,
      version: config.version,
      environment: config.environment,
      instance_type: config.instance_type,
      storage_gb: config.storage_gb,
      tenant_isolation: config.tenant_isolation,
      tenants_count: this.tenants.size,
      max_tenants: config.max_tenants,
      features: {
        backup_enabled: config.features.backup.enabled,
        monitoring_enabled: config.features.monitoring.enabled,
        replication_enabled: config.features.replication.enabled,
        auto_scaling_enabled: config.scaling.auto_scaling
      },
      security: {
        ssl_enabled: config.security.ssl_enabled,
        encryption_at_rest: config.security.encryption_at_rest,
        row_level_security: config.security.row_level_security
      },
      estimated_cost_per_month: this.estimateMonthlyCosting(),
      configuration_files_generated: true,
      kubernetes_ready: true,
      docker_ready: true
    };
  }

  /**
   * Estimate monthly cost (simplified calculation)
   */
  private estimateMonthlyCosting(): number {
    const config = this.template;
    let cost = 0;

    // Base instance cost (simplified)
    const instanceCosts = {
      micro: 20,
      small: 50,
      medium: 120,
      large: 300,
      xlarge: 600
    };

    cost += instanceCosts[config.instance_type] || 0;

    // Storage cost ($0.1 per GB per month)
    cost += config.storage_gb * 0.1;

    // Backup storage (if enabled)
    if (config.features.backup.enabled) {
      cost += config.storage_gb * 0.05; // Backup storage is typically cheaper
    }

    // Replication cost (if enabled)
    if (config.features.replication.enabled) {
      cost += (instanceCosts[config.instance_type] || 0) * config.features.replication.replicas * 0.8;
    }

    return Math.round(cost * 100) / 100;
  }

  /**
   * Export template configuration to JSON
   */
  exportConfig(): string {
    return JSON.stringify({
      template: this.template,
      tenants: Array.from(this.tenants.entries()),
      deployment_history: this.deploymentHistory,
      exported_at: new Date()
    }, null, 2);
  }

  /**
   * Import template configuration from JSON
   */
  importConfig(configJson: string): void {
    try {
      const config = JSON.parse(configJson);
      
      if (config.template) {
        this.template = config.template;
      }
      
      if (config.tenants) {
        this.tenants = new Map(config.tenants);
      }
      
      if (config.deployment_history) {
        this.deploymentHistory = config.deployment_history;
      }
      
      this.template.updated_at = new Date();
    } catch (error) {
      throw new Error(`Failed to import configuration: ${error}`);
    }
  }
}

/**
 * Create a new PostgreSQL template instance
 */
export function createPostgreSQLTemplate(config?: Partial<PostgreSQLTemplate>): PostgreSQLDatabaseTemplate {
  return new PostgreSQLDatabaseTemplate(config);
}

/**
 * Create environment-specific PostgreSQL template
 */
export function createEnvironmentTemplate(
  environment: 'development' | 'staging' | 'production',
  name: string,
  additionalConfig?: Partial<PostgreSQLTemplate>
): PostgreSQLDatabaseTemplate {
  const baseConfig: Partial<PostgreSQLTemplate> = {
    name,
    environment,
    created_at: new Date(),
    ...additionalConfig
  };
  
  return new PostgreSQLDatabaseTemplate(baseConfig);
}

export default PostgreSQLDatabaseTemplate;