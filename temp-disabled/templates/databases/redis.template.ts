/**
 * Redis Advanced Caching Template
 * P3-T02 Implementation for CodeRunner v2.0
 * 
 * Features:
 * - Multi-tenant architecture with key prefix isolation
 * - AgentSphere cloud integration
 * - Advanced caching strategies and performance optimization
 * - High availability clustering and persistence
 * - Auto-scaling and resource management
 * - Comprehensive monitoring and alerting
 */

import {
  RedisTemplate,
  RedisDeploymentResult,
  RedisTenant,
  validateRedisTemplate,
  DEFAULT_REDIS_TEMPLATE,
  REDIS_ENVIRONMENT_PRESETS
} from './redis.config';

/**
 * Redis template class for managing advanced caching deployments
 */
export class RedisCacheTemplate {
  private template: RedisTemplate;
  private tenants: Map<string, RedisTenant>;
  private deploymentHistory: RedisDeploymentResult[];

  constructor(template?: Partial<RedisTemplate>) {
    this.template = {
      ...DEFAULT_REDIS_TEMPLATE,
      ...template
    } as RedisTemplate;
    
    this.tenants = new Map();
    this.deploymentHistory = [];
    
    // Apply environment-specific presets
    if (template?.environment && REDIS_ENVIRONMENT_PRESETS[template.environment]) {
      this.applyEnvironmentPreset(template.environment);
    }
  }

  /**
   * Apply environment-specific configuration preset
   */
  private applyEnvironmentPreset(environment: string): void {
    const preset = REDIS_ENVIRONMENT_PRESETS[environment];
    if (preset) {
      this.template = this.mergeDeep(this.template, preset) as RedisTemplate;
    }
  }

  /**
   * Deep merge two objects
   */
  private mergeDeep(target: any, source: any): any {
    const result = { ...target };
    
    for (const key in source) {
      if (source[key] && typeof source[key] === 'object' && !Array.isArray(source[key])) {
        result[key] = this.mergeDeep(result[key] || {}, source[key]);
      } else {
        result[key] = source[key];
      }
    }
    
    return result;
  }

  /**
   * Get the current template configuration
   */
  getTemplate(): RedisTemplate {
    return { ...this.template };
  }

  /**
   * Update template configuration
   */
  updateTemplate(updates: Partial<RedisTemplate>): void {
    this.template = { ...this.template, ...updates };
    this.template.updated_at = new Date();
  }

  /**
   * Validate the current template configuration
   */
  validate(): { isValid: boolean; errors: { [field: string]: string[] } } {
    return validateRedisTemplate(this.template);
  }

  /**
   * Generate Redis configuration file (redis.conf)
   */
  generateRedisConfig(): string {
    const config = this.template;
    
    return `
# Redis Configuration
# Generated by CodeRunner v2.0 Redis Template
# Template: ${config.name}
# Version: ${config.version}
# Mode: ${config.mode}
# Environment: ${config.environment}

# Network Configuration
bind 0.0.0.0
port 6379
tcp-backlog ${config.connection.tcp_backlog}
timeout ${config.connection.timeout_ms / 1000}
tcp-keepalive ${config.connection.tcp_keepalive}

# General Settings
daemonize no
pidfile /var/run/redis.pid
loglevel ${config.environment === 'production' ? 'notice' : 'verbose'}
logfile ""
databases 16

# Memory Management
maxmemory ${config.memory_mb}mb
maxmemory-policy ${config.features.eviction.policy}
maxmemory-samples ${config.features.eviction.maxmemory_samples}

# Persistence Configuration
${config.features.persistence.enabled ? this.generatePersistenceConfig() : '# Persistence disabled'}

# Replication Configuration
${config.mode === 'cluster' || config.mode === 'sentinel' ? this.generateReplicationConfig() : '# Replication not configured'}

# Client Configuration
maxclients ${config.connection.max_clients}
${this.generateClientOutputBufferLimits()}

# Performance Tuning
${this.generatePerformanceConfig()}

# Security Configuration
${this.generateSecurityConfig()}

# Slow Log Configuration
slowlog-log-slower-than ${config.features.monitoring.slow_log_threshold}
slowlog-max-len 128

# Latency Monitoring
latency-monitor-threshold 100

# Advanced Configuration
${config.features.clustering.enabled ? this.generateClusterConfig() : '# Clustering disabled'}

# Module Loading
${config.modules.map(module => `loadmodule ${module}`).join('\n')}

# Custom Performance Settings
hash-max-ziplist-entries ${config.performance.hash_max_ziplist_entries}
hash-max-ziplist-value ${config.performance.hash_max_ziplist_value}
list-max-ziplist-size ${config.performance.list_max_ziplist_size}
set-max-intset-entries ${config.performance.set_max_intset_entries}
zset-max-ziplist-entries ${config.performance.zset_max_ziplist_entries}
zset-max-ziplist-value ${config.performance.zset_max_ziplist_value}

# Lazy Freeing
lazyfree-lazy-eviction ${config.performance.lazyfree_lazy_eviction ? 'yes' : 'no'}
lazyfree-lazy-expire ${config.performance.lazyfree_lazy_expire ? 'yes' : 'no'}
lazyfree-lazy-server-del ${config.performance.lazyfree_lazy_server_del ? 'yes' : 'no'}
replica-lazy-flush ${config.performance.replica_lazy_flush ? 'yes' : 'no'}

# IO Threads
io-threads ${config.performance.io_threads}
io-threads-do-reads ${config.performance.io_threads_do_reads ? 'yes' : 'no'}

# Rename dangerous commands
${Object.entries(config.security.rename_dangerous_commands)
  .map(([cmd, rename]) => `rename-command ${cmd} ${rename}`)
  .join('\n')}
`;
  }

  /**
   * Generate persistence configuration section
   */
  private generatePersistenceConfig(): string {
    const persistence = this.template.features.persistence;
    let config = '';

    if (persistence.mode === 'rdb' || persistence.mode === 'mixed') {
      config += `
# RDB Persistence
${persistence.rdb_schedule || 'save 900 1 300 10 60 10000'}
stop-writes-on-bgsave-error yes
rdbcompression yes
rdbchecksum yes
dbfilename dump.rdb
dir /data`;
    }

    if (persistence.mode === 'aof' || persistence.mode === 'mixed') {
      config += `
# AOF Persistence
appendonly yes
appendfilename "appendonly.aof"
appendfsync ${persistence.aof_fsync || 'everysec'}
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage ${persistence.aof_rewrite_percentage || 100}
auto-aof-rewrite-min-size ${persistence.aof_rewrite_min_size || '64mb'}
aof-load-truncated yes
aof-use-rdb-preamble yes`;
    }

    return config;
  }

  /**
   * Generate replication configuration section
   */
  private generateReplicationConfig(): string {
    if (this.template.mode === 'cluster') {
      return `
# Cluster Configuration
cluster-enabled yes
cluster-config-file nodes-${this.template.name}.conf
cluster-node-timeout ${this.template.features.clustering.cluster_node_timeout}
cluster-announce-ip ${this.template.features.clustering.cluster_announce_ip || ''}
cluster-announce-port 6379
cluster-announce-bus-port 16379`;
    }

    return '# Replication configuration for sentinel mode would be handled separately';
  }

  /**
   * Generate client output buffer limits
   */
  private generateClientOutputBufferLimits(): string {
    const limits = this.template.connection.client_output_buffer_limit;
    return `
client-output-buffer-limit normal ${limits.normal}
client-output-buffer-limit replica ${limits.replica}
client-output-buffer-limit pubsub ${limits.pubsub}`;
  }

  /**
   * Generate performance configuration section
   */
  private generatePerformanceConfig(): string {
    return `
# Performance Optimization
tcp-nodelay yes
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb`;
  }

  /**
   * Generate security configuration section
   */
  private generateSecurityConfig(): string {
    const security = this.template.security;
    let config = `
# Security Configuration
protected-mode ${security.protected_mode ? 'yes' : 'no'}`;

    if (security.password_enabled && security.password) {
      config += `\nrequirepass ${security.password}`;
    }

    if (security.tls_enabled) {
      config += `
# TLS Configuration
tls-port 6380
port 0
tls-cert-file ${security.tls_cert_file || '/etc/redis/tls/redis.crt'}
tls-key-file ${security.tls_key_file || '/etc/redis/tls/redis.key'}
tls-ca-cert-file ${security.tls_ca_cert_file || '/etc/redis/tls/ca.crt'}`;
    }

    if (security.acl_enabled) {
      config += `
# ACL Configuration
aclfile /etc/redis/users.acl`;
    }

    return config;
  }

  /**
   * Generate cluster configuration section
   */
  private generateClusterConfig(): string {
    if (!this.template.features.clustering.enabled) {
      return '';
    }

    return `
# Cluster Specific Settings
cluster-require-full-coverage yes
cluster-allow-reads-when-down no
cluster-migration-barrier 1`;
  }

  /**
   * Generate Docker Compose configuration for Redis
   */
  generateDockerCompose(): string {
    const config = this.template;
    
    if (config.mode === 'cluster') {
      return this.generateClusterDockerCompose();
    }

    return `
version: '3.8'

services:
  redis-${config.name}:
    image: redis:${config.version}-alpine
    container_name: redis-${config.name}
    restart: always
    command: redis-server /usr/local/etc/redis/redis.conf
    ports:
      - "6379:6379"
      ${config.security.tls_enabled ? '- "6380:6380"' : ''}
    volumes:
      - redis_data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf:ro
      ${config.security.tls_enabled ? `
      - ./tls:/etc/redis/tls:ro` : ''}
      ${config.security.acl_enabled ? `
      - ./users.acl:/etc/redis/users.acl:ro` : ''}
    environment:
      - REDIS_REPLICATION_MODE=${config.mode}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - redis_network
    ${config.scaling.auto_scaling ? `deploy:
      resources:
        limits:
          memory: ${config.memory_mb}M
        reservations:
          memory: ${Math.floor(config.memory_mb * 0.7)}M` : ''}

  ${config.features.monitoring.enabled ? `redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-exporter-${config.name}
    restart: always
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://${config.security.password_enabled ? ':' + (config.security.password || 'password') + '@' : ''}redis-${config.name}:6379
      - REDIS_EXPORTER_INCL_SYSTEM_METRICS=true
    depends_on:
      - redis-${config.name}
    networks:
      - redis_network` : ''}

  ${config.backup.enabled ? `redis-backup:
    image: alpine:latest
    container_name: redis-backup-${config.name}
    restart: always
    volumes:
      - redis_data:/data:ro
      - redis_backups:/backups
      - ./backup.sh:/opt/scripts/backup.sh:ro
    environment:
      - REDIS_HOST=redis-${config.name}
      - REDIS_PORT=6379
      - BACKUP_SCHEDULE=${config.backup.schedule}
      - RETENTION_DAYS=${config.backup.retention_days}
    depends_on:
      - redis-${config.name}
    networks:
      - redis_network
    command: crond -f -d 8` : ''}

volumes:
  redis_data:
    driver: local
  ${config.backup.enabled ? 'redis_backups:\n    driver: local' : ''}

networks:
  redis_network:
    driver: bridge
`;
  }

  /**
   * Generate Docker Compose configuration for Redis Cluster
   */
  private generateClusterDockerCompose(): string {
    const config = this.template;
    const clustering = config.features.clustering;
    const totalNodes = clustering.shards * (clustering.replicas_per_shard + 1);
    
    let services = '';
    let volumes = '';
    
    // Generate nodes for cluster
    for (let i = 1; i <= totalNodes; i++) {
      const port = 6378 + i;
      services += `
  redis-node-${i}:
    image: redis:${config.version}-alpine
    container_name: redis-node-${i}-${config.name}
    restart: always
    command: redis-server /usr/local/etc/redis/redis.conf
    ports:
      - "${port}:6379"
      - "${port + 10000}:16379"
    volumes:
      - redis_data_${i}:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - redis_cluster_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
`;
      
      volumes += `
  redis_data_${i}:
    driver: local`;
    }

    return `
version: '3.8'

services:${services}

  redis-cluster-init:
    image: redis:${config.version}-alpine
    container_name: redis-cluster-init-${config.name}
    depends_on:
      ${Array.from({length: totalNodes}, (_, i) => `- redis-node-${i + 1}`).join('\n      ')}
    networks:
      - redis_cluster_network
    command: >
      redis-cli --cluster create
      ${Array.from({length: totalNodes}, (_, i) => `redis-node-${i + 1}:6379`).join(' ')}
      --cluster-replicas ${clustering.replicas_per_shard}
      --cluster-yes
    restart: "no"

  ${config.features.monitoring.enabled ? `redis-cluster-exporter:
    image: oliver006/redis_exporter:latest
    container_name: redis-cluster-exporter-${config.name}
    restart: always
    ports:
      - "9121:9121"
    environment:
      - REDIS_ADDR=redis://redis-node-1:6379
      - REDIS_EXPORTER_IS_CLUSTER=true
    depends_on:
      - redis-cluster-init
    networks:
      - redis_cluster_network` : ''}

volumes:${volumes}

networks:
  redis_cluster_network:
    driver: bridge
`;
  }

  /**
   * Generate ACL users file for Redis
   */
  generateACLUsersFile(): string {
    if (!this.template.security.acl_enabled || !this.template.security.acl_users) {
      return '';
    }

    let aclConfig = '# Redis ACL Users Configuration\n';
    
    this.template.security.acl_users.forEach(user => {
      aclConfig += `user ${user.username} on >${user.password} `;
      aclConfig += `~${user.keys.join(' ~')} `;
      aclConfig += `+${user.commands.join(' +')} `;
      aclConfig += `-@all\n`;
    });

    return aclConfig;
  }

  /**
   * Generate Kubernetes deployment manifests
   */
  generateKubernetesManifests(): { [filename: string]: string } {
    const config = this.template;
    const manifests: { [filename: string]: string } = {};

    // ConfigMap for Redis configuration
    manifests['redis-config.yaml'] = `
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config-${config.name}
  labels:
    app: redis
    template: ${config.name}
data:
  redis.conf: |
${this.generateRedisConfig().split('\n').map(line => '    ' + line).join('\n')}
`;

    // Secret for Redis credentials
    manifests['redis-secret.yaml'] = `
apiVersion: v1
kind: Secret
metadata:
  name: redis-secret-${config.name}
  labels:
    app: redis
    template: ${config.name}
type: Opaque
data:
  redis-password: \${REDIS_PASSWORD_BASE64}
`;

    if (config.mode === 'cluster') {
      manifests['redis-cluster.yaml'] = this.generateKubernetesClusterManifests();
    } else {
      manifests['redis-deployment.yaml'] = this.generateKubernetesStandaloneManifests();
    }

    // Service
    manifests['redis-service.yaml'] = `
apiVersion: v1
kind: Service
metadata:
  name: redis-${config.name}
  labels:
    app: redis
    template: ${config.name}
spec:
  ports:
  - port: 6379
    targetPort: 6379
    protocol: TCP
    name: redis
  ${config.security.tls_enabled ? `- port: 6380
    targetPort: 6380
    protocol: TCP
    name: redis-tls` : ''}
  selector:
    app: redis
    template: ${config.name}
  type: ClusterIP
`;

    return manifests;
  }

  /**
   * Generate Kubernetes standalone deployment
   */
  private generateKubernetesStandaloneManifests(): string {
    const config = this.template;

    return `
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-${config.name}
  labels:
    app: redis
    template: ${config.name}
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      template: ${config.name}
  template:
    metadata:
      labels:
        app: redis
        template: ${config.name}
    spec:
      containers:
      - name: redis
        image: redis:${config.version}-alpine
        ports:
        - containerPort: 6379
          name: redis
        ${config.security.tls_enabled ? `- containerPort: 6380
          name: redis-tls` : ''}
        command:
        - redis-server
        - /usr/local/etc/redis/redis.conf
        volumeMounts:
        - name: redis-config
          mountPath: /usr/local/etc/redis/redis.conf
          subPath: redis.conf
        - name: redis-data
          mountPath: /data
        resources:
          requests:
            memory: "${Math.floor(config.memory_mb * 0.7)}Mi"
            cpu: "100m"
          limits:
            memory: "${config.memory_mb}Mi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: redis-config
        configMap:
          name: redis-config-${config.name}
      - name: redis-data
        persistentVolumeClaim:
          claimName: redis-data-${config.name}
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: redis-data-${config.name}
  labels:
    app: redis
    template: ${config.name}
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: ${Math.ceil(config.memory_mb / 1024)}Gi
`;
  }

  /**
   * Generate Kubernetes cluster deployment
   */
  private generateKubernetesClusterManifests(): string {
    const config = this.template;
    const clustering = config.features.clustering;
    
    return `
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster-${config.name}
  labels:
    app: redis-cluster
    template: ${config.name}
spec:
  serviceName: redis-cluster-${config.name}
  replicas: ${clustering.shards * (clustering.replicas_per_shard + 1)}
  selector:
    matchLabels:
      app: redis-cluster
      template: ${config.name}
  template:
    metadata:
      labels:
        app: redis-cluster
        template: ${config.name}
    spec:
      containers:
      - name: redis
        image: redis:${config.version}-alpine
        ports:
        - containerPort: 6379
          name: redis
        - containerPort: 16379
          name: cluster-bus
        command:
        - redis-server
        - /usr/local/etc/redis/redis.conf
        volumeMounts:
        - name: redis-config
          mountPath: /usr/local/etc/redis/redis.conf
          subPath: redis.conf
        - name: redis-data
          mountPath: /data
        resources:
          requests:
            memory: "${Math.floor(config.memory_mb / clustering.shards * 0.7)}Mi"
            cpu: "100m"
          limits:
            memory: "${Math.floor(config.memory_mb / clustering.shards)}Mi"
            cpu: "300m"
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: redis-config
        configMap:
          name: redis-config-${config.name}
  volumeClaimTemplates:
  - metadata:
      name: redis-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: ${Math.ceil(config.memory_mb / clustering.shards / 1024)}Gi
---
apiVersion: v1
kind: Service
metadata:
  name: redis-cluster-${config.name}
  labels:
    app: redis-cluster
    template: ${config.name}
spec:
  ports:
  - port: 6379
    targetPort: 6379
    protocol: TCP
    name: redis
  - port: 16379
    targetPort: 16379
    protocol: TCP
    name: cluster-bus
  clusterIP: None
  selector:
    app: redis-cluster
    template: ${config.name}
`;
  }

  /**
   * Generate backup and recovery scripts
   */
  generateBackupScripts(): { [filename: string]: string } {
    const config = this.template;
    const scripts: { [filename: string]: string } = {};

    if (!config.backup.enabled) {
      return scripts;
    }

    scripts['backup.sh'] = `#!/bin/bash
# Redis Backup Script
# Template: ${config.name}
# Generated by CodeRunner v2.0

set -euo pipefail

# Configuration
REDIS_HOST="\${REDIS_HOST:-localhost}"
REDIS_PORT="\${REDIS_PORT:-6379}"
REDIS_PASSWORD="\${REDIS_PASSWORD:-}"
BACKUP_DIR="/backups"
RETENTION_DAYS=${config.backup.retention_days}
COMPRESSION=${config.backup.compression}
ENCRYPTION=${config.backup.encryption_enabled}

# Create backup directory
mkdir -p "\$BACKUP_DIR"

# Generate timestamp
TIMESTAMP=\$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="\$BACKUP_DIR/redis-${config.name}_\$TIMESTAMP"

# Function to log messages
log() {
    echo "[\$(date '+%Y-%m-%d %H:%M:%S')] \$1" | tee -a "\$BACKUP_DIR/backup.log"
}

# Function to cleanup old backups
cleanup_old_backups() {
    log "Cleaning up backups older than \$RETENTION_DAYS days"
    find "\$BACKUP_DIR" -name "redis-${config.name}_*" -type f -mtime +\$RETENTION_DAYS -delete
    log "Cleanup completed"
}

# Function to compress backup
compress_backup() {
    local file=\$1
    if [ "\$COMPRESSION" = "true" ]; then
        log "Compressing backup"
        gzip "\$file"
        echo "\${file}.gz"
    else
        echo "\$file"
    fi
}

# Function to encrypt backup
encrypt_backup() {
    local file=\$1
    if [ "\$ENCRYPTION" = "true" ]; then
        log "Encrypting backup"
        openssl enc -aes-256-cbc -salt -in "\$file" -out "\${file}.enc" -k "\$BACKUP_ENCRYPTION_KEY"
        rm "\$file"
        echo "\${file}.enc"
    else
        echo "\$file"
    fi
}

# Main backup function
perform_backup() {
    log "Starting Redis backup for ${config.name}"
    
    # Create RDB snapshot
    if [ -n "\$REDIS_PASSWORD" ]; then
        redis-cli -h "\$REDIS_HOST" -p "\$REDIS_PORT" -a "\$REDIS_PASSWORD" --rdb "\${BACKUP_FILE}.rdb"
    else
        redis-cli -h "\$REDIS_HOST" -p "\$REDIS_PORT" --rdb "\${BACKUP_FILE}.rdb"
    fi
    
    # Process the backup file
    FINAL_FILE="\${BACKUP_FILE}.rdb"
    FINAL_FILE=\$(compress_backup "\$FINAL_FILE")
    FINAL_FILE=\$(encrypt_backup "\$FINAL_FILE")
    
    # Calculate backup size and checksum
    BACKUP_SIZE=\$(du -h "\$FINAL_FILE" | cut -f1)
    BACKUP_CHECKSUM=\$(sha256sum "\$FINAL_FILE" | cut -d' ' -f1)
    
    log "Backup completed: \$FINAL_FILE (\$BACKUP_SIZE)"
    log "Checksum: \$BACKUP_CHECKSUM"
    
    ${config.backup.s3_bucket ? `
    # Upload to S3 if configured
    if [ -n "\${AWS_ACCESS_KEY_ID:-}" ] && [ -n "\${AWS_SECRET_ACCESS_KEY:-}" ]; then
        log "Uploading backup to S3"
        aws s3 cp "\$FINAL_FILE" "s3://${config.backup.s3_bucket}${config.backup.s3_path || '/'}/"
        log "Upload completed"
    fi
    ` : ''}
}

# Main execution
main() {
    log "Backup process started for ${config.name}"
    
    # Check prerequisites
    if ! command -v redis-cli &> /dev/null; then
        log "ERROR: redis-cli is not available"
        exit 1
    fi
    
    # Perform backup
    perform_backup
    
    # Cleanup old backups
    cleanup_old_backups
    
    log "Backup process completed successfully"
}

# Error handling
trap 'log "ERROR: Backup process failed at line \$LINENO"; exit 1' ERR

# Run main function
main "\$@"
`;

    scripts['restore.sh'] = `#!/bin/bash
# Redis Restore Script
# Template: ${config.name}
# Generated by CodeRunner v2.0

set -euo pipefail

# Configuration
REDIS_HOST="\${REDIS_HOST:-localhost}"
REDIS_PORT="\${REDIS_PORT:-6379}"
REDIS_PASSWORD="\${REDIS_PASSWORD:-}"
BACKUP_DIR="/backups"

# Function to log messages
log() {
    echo "[\$(date '+%Y-%m-%d %H:%M:%S')] \$1"
}

# Function to list available backups
list_backups() {
    log "Available backups:"
    ls -la "\$BACKUP_DIR"/redis-${config.name}_* 2>/dev/null || log "No backups found"
}

# Function to restore from backup
restore_backup() {
    local backup_file=\$1
    
    if [ ! -f "\$backup_file" ]; then
        log "ERROR: Backup file not found: \$backup_file"
        exit 1
    fi
    
    log "Restoring Redis from \$backup_file"
    
    # Decrypt if needed
    if [[ "\$backup_file" == *.enc ]]; then
        log "Decrypting backup"
        openssl enc -d -aes-256-cbc -in "\$backup_file" -out "\${backup_file%.enc}" -k "\$BACKUP_ENCRYPTION_KEY"
        backup_file="\${backup_file%.enc}"
    fi
    
    # Decompress if needed
    if [[ "\$backup_file" == *.gz ]]; then
        log "Decompressing backup"
        gunzip "\$backup_file"
        backup_file="\${backup_file%.gz}"
    fi
    
    # Stop Redis (if running locally)
    log "Flushing current Redis data"
    if [ -n "\$REDIS_PASSWORD" ]; then
        redis-cli -h "\$REDIS_HOST" -p "\$REDIS_PORT" -a "\$REDIS_PASSWORD" FLUSHALL
    else
        redis-cli -h "\$REDIS_HOST" -p "\$REDIS_PORT" FLUSHALL
    fi
    
    # Restore from RDB file
    log "Loading RDB file"
    if [ -n "\$REDIS_PASSWORD" ]; then
        redis-cli -h "\$REDIS_HOST" -p "\$REDIS_PORT" -a "\$REDIS_PASSWORD" --pipe < "\$backup_file" || \
        redis-cli -h "\$REDIS_HOST" -p "\$REDIS_PORT" -a "\$REDIS_PASSWORD" DEBUG RESTART
    else
        redis-cli -h "\$REDIS_HOST" -p "\$REDIS_PORT" --pipe < "\$backup_file" || \
        redis-cli -h "\$REDIS_HOST" -p "\$REDIS_PORT" DEBUG RESTART
    fi
    
    log "Restore completed successfully"
}

# Main function
main() {
    if [ "\$#" -eq 0 ]; then
        list_backups
        echo ""
        echo "Usage: \$0 <backup_file>"
        echo "Example: \$0 /backups/redis-${config.name}_20240101_120000.rdb"
        exit 1
    fi
    
    restore_backup "\$1"
}

main "\$@"
`;

    return scripts;
  }

  /**
   * Add a new tenant to the Redis instance
   */
  addTenant(tenantId: string, options: Partial<RedisTenant> = {}): RedisTenant {
    const keyPrefix = this.template.tenant_config.key_prefix_pattern.replace('{tenantId}', tenantId);
    
    const tenant: RedisTenant = {
      tenant_id: tenantId,
      key_prefix: keyPrefix,
      database_number: this.template.tenant_config.isolation_type === 'database' ? 
        this.tenants.size : undefined,
      created_at: new Date(),
      resource_limits: {
        max_memory_mb: this.template.tenant_config.tenant_resource_limits.max_memory_per_tenant_mb,
        max_connections: this.template.tenant_config.tenant_resource_limits.max_connections_per_tenant,
        max_ops_per_second: this.template.tenant_config.tenant_resource_limits.max_ops_per_second_per_tenant,
        max_keys: 100000
      },
      access_config: {
        allowed_commands: ['GET', 'SET', 'DEL', 'EXISTS', 'EXPIRE', 'TTL', 'KEYS'],
        forbidden_commands: ['FLUSHDB', 'FLUSHALL', 'CONFIG', 'DEBUG'],
        key_patterns: [keyPrefix + '*'],
        read_only: false
      },
      caching_config: {
        default_ttl: this.template.features.caching_strategy.ttl_strategy.default_ttl_seconds,
        max_ttl: this.template.features.caching_strategy.ttl_strategy.max_ttl_seconds,
        eviction_policy: this.template.features.eviction.policy
      },
      status: 'active',
      ...options
    };

    this.tenants.set(tenantId, tenant);
    return tenant;
  }

  /**
   * Remove a tenant from the Redis instance
   */
  removeTenant(tenantId: string): boolean {
    if (!this.tenants.has(tenantId)) {
      return false;
    }

    const tenant = this.tenants.get(tenantId)!;
    tenant.status = 'deleting';
    
    // In a real implementation, this would trigger key cleanup
    this.tenants.delete(tenantId);
    return true;
  }

  /**
   * Get all tenants
   */
  getTenants(): RedisTenant[] {
    return Array.from(this.tenants.values());
  }

  /**
   * Get tenant by ID
   */
  getTenant(tenantId: string): RedisTenant | undefined {
    return this.tenants.get(tenantId);
  }

  /**
   * Generate deployment summary
   */
  getDeploymentSummary(): any {
    const config = this.template;
    
    return {
      template_name: config.name,
      version: config.version,
      mode: config.mode,
      environment: config.environment,
      instance_type: config.instance_type,
      memory_mb: config.memory_mb,
      tenant_isolation: config.tenant_config.isolation_type,
      tenants_count: this.tenants.size,
      max_tenants: config.tenant_config.max_tenants,
      features: {
        persistence_enabled: config.features.persistence.enabled,
        persistence_mode: config.features.persistence.mode,
        clustering_enabled: config.features.clustering.enabled,
        monitoring_enabled: config.features.monitoring.enabled,
        auto_scaling_enabled: config.scaling.auto_scaling,
        backup_enabled: config.backup.enabled
      },
      security: {
        password_enabled: config.security.password_enabled,
        acl_enabled: config.security.acl_enabled,
        tls_enabled: config.security.tls_enabled,
        protected_mode: config.security.protected_mode
      },
      caching_strategy: {
        patterns: config.features.caching_strategy.patterns,
        default_ttl: config.features.caching_strategy.ttl_strategy.default_ttl_seconds,
        compression_enabled: config.features.caching_strategy.compression.enabled
      },
      estimated_cost_per_month: this.estimateMonthlyCosting(),
      configuration_files_generated: true,
      kubernetes_ready: true,
      docker_ready: true,
      cluster_ready: config.features.clustering.enabled
    };
  }

  /**
   * Estimate monthly cost (simplified calculation)
   */
  private estimateMonthlyCosting(): number {
    const config = this.template;
    let cost = 0;

    // Base instance cost (simplified)
    const instanceCosts: { [key: string]: number } = {
      'cache.t3.micro': 15,
      'cache.t3.small': 35,
      'cache.t3.medium': 70,
      'cache.m6i.large': 150,
      'cache.m6i.xlarge': 300,
      'cache.r6g.large': 180
    };

    cost += instanceCosts[config.instance_type] || 35;

    // Memory cost (additional for larger instances)
    if (config.memory_mb > 2048) {
      cost += (config.memory_mb - 2048) * 0.01;
    }

    // Clustering cost
    if (config.features.clustering.enabled) {
      const clusterMultiplier = config.features.clustering.shards * 
        (config.features.clustering.replicas_per_shard + 1);
      cost *= clusterMultiplier * 0.9; // 10% discount for cluster efficiency
    }

    // Backup cost
    if (config.backup.enabled) {
      cost += (config.memory_mb / 1024) * 5; // $5 per GB per month for backups
    }

    // Monitoring cost
    if (config.features.monitoring.enabled) {
      cost += 10; // Fixed monitoring cost
    }

    return Math.round(cost * 100) / 100;
  }

  /**
   * Export template configuration to JSON
   */
  exportConfig(): string {
    return JSON.stringify({
      template: this.template,
      tenants: Array.from(this.tenants.entries()),
      deployment_history: this.deploymentHistory,
      exported_at: new Date()
    }, null, 2);
  }

  /**
   * Import template configuration from JSON
   */
  importConfig(configJson: string): void {
    try {
      const config = JSON.parse(configJson);
      
      if (config.template) {
        this.template = config.template;
      }
      
      if (config.tenants) {
        this.tenants = new Map(config.tenants);
      }
      
      if (config.deployment_history) {
        this.deploymentHistory = config.deployment_history;
      }
      
      this.template.updated_at = new Date();
    } catch (error) {
      throw new Error(`Failed to import configuration: ${error}`);
    }
  }

  /**
   * Generate Redis CLI commands for tenant operations
   */
  generateTenantCommands(tenantId: string): string[] {
    const tenant = this.getTenant(tenantId);
    if (!tenant) {
      return [];
    }

    const commands: string[] = [];
    
    // Create ACL user for tenant if ACL is enabled
    if (this.template.security.acl_enabled) {
      commands.push(
        `ACL SETUSER ${tenantId} on >${tenant.tenant_id}_password ` +
        `~${tenant.key_prefix}* ` +
        `+${tenant.access_config.allowed_commands.join(' +')} ` +
        `-${tenant.access_config.forbidden_commands.join(' -')}`
      );
    }

    // Set resource limits using CLIENT TRACKING or custom Lua scripts
    commands.push(
      `CONFIG SET maxmemory-samples ${this.template.features.eviction.maxmemory_samples}`,
      `CONFIG SET maxmemory-policy ${tenant.caching_config.eviction_policy}`
    );

    return commands;
  }
}

/**
 * Create a new Redis template instance
 */
export function createRedisTemplate(config?: Partial<RedisTemplate>): RedisCacheTemplate {
  return new RedisCacheTemplate(config);
}

/**
 * Create environment-specific Redis template
 */
export function createEnvironmentRedisTemplate(
  environment: 'development' | 'staging' | 'production',
  name: string,
  additionalConfig?: Partial<RedisTemplate>
): RedisCacheTemplate {
  const baseConfig: Partial<RedisTemplate> = {
    name,
    environment,
    created_at: new Date(),
    ...additionalConfig
  };
  
  return new RedisCacheTemplate(baseConfig);
}

export default RedisCacheTemplate;